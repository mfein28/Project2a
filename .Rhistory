kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F, position = "left") %>%
column_spec(1, color = "red")
fig1 <- ggplot(crime, aes(x = WARD, fill = proper(as.character(OFFENSE)))) +
geom_bar() +
theme_bw() +
labs(x = "Ward",
y = "Frequency",
fill = "Type of Offense") +
scale_x_discrete(limits = c(1:8, "1"))
print(fig1 + ggtitle("Frequency of Offense by Type and Ward"))
pie_input <- as.data.frame(cbind(WARD, TOTAL)) %>%
arrange(WARD)
fig2 <- plot_ly(pie_input,
labels = ~WARD,
values = ~TOTAL,
textinfo = "percent",
text = ~paste("Ward", WARD),
hoverinfo = "text",
type = "pie",
textposition = "outside") %>%
layout(title = "Percentage Breakdown of Total Crimes by Ward")
fig2
library(dplyr)
library(car)
library(corrplot)
library(ggplot2)
library(corrplot)
listingsreg<-dplyr::select(listings,9:17)
listingsreg<-dplyr::select(listingsreg,-last_review,-room_type, -reviews_per_month)
Listingscor<-cor(listingsreg)
colnames(Listingscor) <- c("Price", "Min. Nights", "# of Reviews", "Host Listings Count", "Availability", "Neighborhood Count")
rownames(Listingscor) <- c("Price", "Min. Nights", "# of Reviews", "Host Listings Count", "Availability", "Neighborhood Count")
corrplot(Listingscor, method = "shade")
outlierKD <- function(dt, var) {
var_name <- eval(substitute(var),eval(dt))
na1 <- sum(is.na(var_name))
m1 <- mean(var_name, na.rm = T)
par(mfrow=c(2, 2), oma=c(0,0,3,0))
boxplot(var_name, main="With outliers")
hist(var_name, main="With outliers", xlab=NA, ylab=NA)
outlier <- boxplot.stats(var_name)$out
mo <- mean(outlier)
var_name <- ifelse(var_name %in% outlier, NA, var_name)
boxplot(var_name, main="Without outliers")
hist(var_name, main="Without outliers", xlab=NA, ylab=NA)
title("Outlier Check", outer=TRUE)
na2 <- sum(is.na(var_name))
cat("Outliers identified:", na2 - na1, "n")
cat("Propotion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name))*100, 1), "n")
cat("Mean of the outliers:", round(mo, 2), "n")
m2 <- mean(var_name, na.rm = T)
cat("Mean without removing outliers:", round(m1, 2), "n")
cat("Mean if we remove outliers:", round(m2, 2), "n")
# response <- readline(prompt="Do you want to remove outliers and to replace with NA? [yes/no]: ")
response <- "yes"
if(response == "y" | response == "yes"){
dt[as.character(substitute(var))] <- invisible(var_name)
assign(as.character(as.list(match.call())$dt), dt, envir = .GlobalEnv)
cat("Outliers successfully removed", "n")
return(invisible(dt))
} else{
cat("Nothing changed", "n")
return(invisible(var_name))
}
}
listingsregtrim <- outlierKD(listingsreg, price)
loadPkg("ggplot2")
datafit1<- data.frame(listingsregtrim)
datafit2<- data.frame(listingsregtrim)
datafit3<- data.frame(listingsregtrim)
datafit4<- data.frame(listingsregtrim)
datafit5<- data.frame(listingsregtrim)
ggplot(datafit1) +
geom_point(aes(number_of_reviews, price), color="blue") +
labs(title = "Price vs. Number of Reviews",
x = "Number of Reviews",
y = "Price") +
theme_bw()
loadPkg("memisc")
fit1 <- lm(price ~ number_of_reviews  , data = datafit1)
reg_table <- mtable("Model 1" = fit1,
summary.stats = c("R-squared", "F", "p", "N"))
reg_table <-
relabel(reg_table,
"(Intercept)" = "Constant",
number_of_reviews = "Number of Reviews")
reg_table
fit2 <- lm(price ~ number_of_reviews + calculated_host_listings_count , data = datafit2)
fit3 <- lm(price ~ number_of_reviews + calculated_host_listings_count + minimum_nights , data = datafit3)
fit4 <- lm(price ~ number_of_reviews + calculated_host_listings_count + minimum_nights + availability_365 , data = datafit4)
fit5 <- lm(price ~ number_of_reviews + calculated_host_listings_count + minimum_nights + availability_365 + neighbourhoodCount, data = datafit5)
reg_table <- mtable("Model 1" = fit1,
"Model 2" = fit2,
"Model 3" = fit3,
"Model 4" = fit4,
"Model 5" = fit5,
summary.stats = c("R-squared", "F", "p", "N"))
reg_table <-
relabel(reg_table,
"(Intercept)" = "Constant",
number_of_reviews = "Number of Reviews",
calculated_host_listings_count = "Host Listings Count",
minimum_nights = "Min. Nights",
availability_365 = "Availability",
neighbourhoodCount = "Neighborhood Count")
reg_table
data("zipcode")
zipcode <- zipcode %>%
filter(state == "DC") %>%
select(zip, latitude, longitude)
# Join zip code with crime dataset
zipcode$latitude <- round(zipcode$latitude, 2)
zipcode$longitude <- round(zipcode$longitude, 2)
crime$LATITUDE <- round(crime$LATITUDE, 2)
crime$LONGITUDE <- round(crime$LONGITUDE, 2)
crime <- left_join(crime, zipcode, by = c("LATITUDE" = "latitude", "LONGITUDE" = "longitude"))
crime <- crime[!duplicated(crime$uniqueID), ]
crime <- subset(crime, !is.na(crime$zip))
# Join zip code with listings dataset
listings$latitude <- round(listings$latitude, 2)
listings$longitude <- round(listings$longitude, 2)
listings <- left_join(listings, zipcode, by = c("latitude", "longitude"))
listings <- listings[!duplicated(listings$id), ]
listings <- subset(listings, !is.na(listings$zip))
# Join listings with crime dataset by zip code
crime_listings <- left_join(listings, crime, by = "zip")
crime_listings_no_dup <- crime_listings[!duplicated(crime_listings$uniqueID), ] # 13,775 observations
crime_count <- crime_listings_no_dup %>%
filter(!is.na(zip)) %>%
select(id, zip, price, OFFENSE) %>%
group_by(zip, as.character(OFFENSE)) %>%
summarise(count = n()) %>%
ungroup() %>%
group_by(zip) %>%
summarise_at(vars(count), list(sum)) %>%
arrange(desc(count))
fig3 <- plot_ly(crime_count[1:10, ],
labels = ~zip,
values = ~count,
textinfo = "percent",
text = ~paste(comma(count), "total crimes"),
hoverinfo = "text",
type = "pie",
textposition = "outside") %>%
layout(title = "Percentage Breakdown Crimes in Top Ten Zip Codes")
fig3
summ_table_input <- listings %>%
select(zip, price) %>%
filter(zip == "20004" | zip == "20010" | zip == "20009" | zip == "20002") %>%
filter(price < 1500)
fig4 <- ggplot(summ_table_input, aes(x = zip, y = price, fill = zip)) +
geom_boxplot() +
theme_bw() +
labs(x = "Zip Code",
y = "Price",
fill = "Zip Code")
print(fig4 + ggtitle("Boxplot of Listing Prices by Zip Code"))
options(qwraps2_markup = "markdown")
summ_table <-
list("Price" =
list("min" = ~min(.data$price),
"max" = ~max(.data$price),
"median" = ~median(.data$price),
"mean (sd)" = ~qwraps2::mean_sd(.data$price)))
tab <- summary_table(dplyr::group_by(summ_table_input, zip), summ_table)
print(tab,
rtitle = "Summary Statistics",
cnames = c("20002 (low)", "20004 (high)", "20009 (low)", "20010 (high)"))
crime_rates <- crime %>%
select(zip, OFFENSE) %>%
group_by(zip) %>%
mutate(arson_rate = sum(OFFENSE == "ARSON") / nrow(crime) * 100,
assualt_rate = sum(OFFENSE == "ASSAULT W/DANGEROUS WEAPON") / nrow(crime) * 100,
burglary_rate = sum(OFFENSE == "BURGLARY") / nrow(crime) * 100,
homicide_rate = sum(OFFENSE == "HOMICIDE") / nrow(crime) * 100,
motorTheft_rate = sum(OFFENSE == "MOTOR VEHICLE THEFT") / nrow(crime) * 100,
robbery_rate = sum(OFFENSE == "ROBBERY") / nrow(crime) * 100,
sexAbuse_rate = sum(OFFENSE == "SEX ABUSE") / nrow(crime) * 100,
theftAuto_rate = sum(OFFENSE == "THEFT F/AUTO") / nrow(crime) * 100,
theftOther_rate = sum(OFFENSE == "THEFT/OTHER") / nrow(crime) * 100)
lm1_input <- left_join(listings, crime_rates, by = "zip")
lm1_input <- lm1_input %>%
group_by(id) %>%
mutate(total_crimes = n()) %>%
filter(!duplicated(id))
lm1 <- lm(price~total_crimes, lm1_input)
reg_table <- mtable("Model 1" = lm1,
summary.stats = c("R-squared", "F", "p", "N"))
reg_table <-
relabel(reg_table,
"(Intercept)" = "Constant",
total_crimes = "Crimes")
reg_table
lm2 <- lm(price~theftOther_rate + theftAuto_rate + robbery_rate + motorTheft_rate,
data = lm1_input)
lm3 <- lm(price~theftOther_rate +
theftAuto_rate +
robbery_rate +
motorTheft_rate +
number_of_reviews +
as.factor(room_type),
data = lm1_input)
reg_table <- mtable("Model 1" = lm1,
"Model 2" = lm2,
"Model 3" = lm3,
summary.stats = c("R-squared", "F", "p", "N"))
reg_table <-
relabel(reg_table,
"(Intercept)" = "Constant",
total_crimes = "Crimes",
theftAuto_rate = "Theft (from auto)",
theftOther_rate = "Theft (other)",
robbery_rate = "Robbery",
motorTheft_rate = "Motor Theft",
number_of_reviews = "Number of Reviews",
`as.factor(room_type): Private room/Entire home/apt` = "Private Room/Entire Home/Apt",
`as.factor(room_type): Shared room/Entire home/apt` = "Shared Room/Entire Home/Apt")
reg_table
data <- read.csv(file = "listings.csv", header = TRUE)
data1<- data[,-5]
data2 <- na.omit(data1)
data3 <- data2[,c(9,10,11,13,14,15)]
cor(data3)
pairs(data3)
model <- lm(price ~ room_type + number_of_reviews + availability_365 + minimum_nights + reviews_per_month + calculated_host_listings_count, data = data)
reg_table <- mtable("Model 1" = model,
summary.stats = c("R-squared", "F", "p", "N"))
reg_table <-
relabel(reg_table,
"(Intercept)" = "Constant",
`room_type: Private room/Entire home/apt` = "Private Room/Entire Home/Apt",
`room_type: Shared room/Entire home/apt` = "Shared Room/Entire Home/Apt",
number_of_reviews = "Number of Reviews",
availability_365 = "Availability",
minimum_nights = "Min. Nights",
reviews_per_month = "Reviews Per Month",
calculated_host_listings_count = "Host Listings Count")
reg_table
plot(model, las = 1)
car::vif(model)
data4<- data[-c(497,1302,1967,3211,3213,3245,3820, 8064),]
model2 <- lm(price ~ room_type + number_of_reviews + availability_365 + minimum_nights + reviews_per_month + calculated_host_listings_count, data = data4)
reg_table <- mtable("Model 1" = model,
"Model 2" = model2,
summary.stats = c("R-squared", "F", "p", "N"))
reg_table <-
relabel(reg_table,
"(Intercept)" = "Constant",
`room_type: Private room/Entire home/apt` = "Private Room/Entire Home/Apt",
`room_type: Shared room/Entire home/apt` = "Shared Room/Entire Home/Apt",
number_of_reviews = "Number of Reviews",
availability_365 = "Availability",
minimum_nights = "Min. Nights",
reviews_per_month = "Reviews Per Month",
calculated_host_listings_count = "Host Listings Count")
reg_table
plot(model2, las = 1)
car::vif(model2)
predict(model2,data.frame (room_type = "Entire home/apt",number_of_reviews = c(10), availability_365 = c(365), minimum_nights = c(1), reviews_per_month = c(0.5), calculated_host_listings_count = c(1)))
predict(model2,data.frame (room_type = "Private room",number_of_reviews = c(10), availability_365 = c(365), minimum_nights = c(1), reviews_per_month = c(0.5), calculated_host_listings_count = c(1)))
predict(model2,data.frame (room_type = "Shared room",number_of_reviews = c(10), availability_365 = c(365), minimum_nights = c(1), reviews_per_month = c(0.5), calculated_host_listings_count = c(1)))
loadPkg("data.table")
loadPkg("rattle")
loadPkg("rpart.plot")
# Load datasets
listings <- read.csv("listings.csv")
neighborhoodClusters <- read.csv("neighborhood_clusters.csv")
crime <- read_csv("crime.csv")
# Added neighborhood cluster to crime
tableCrime <- as.data.frame(table(crime$NEIGHBORHOOD_CLUSTER))
names(tableCrime) <- c("NAME", "Total")
# Join neighborhood clusters to listings data
neighborhoodClusters <- left_join(tableCrime, neighborhoodClusters, by="NAME" )
neighborhoodClusters <- subset(neighborhoodClusters, select=c("NAME", "NBH_NAMES", "Total"))
neighborhoodClusters <- neighborhoodClusters[-1,]
names(neighborhoodClusters) <- c('Cluster', 'neighbourhood', "Total")
listings <- left_join(neighborhoodClusters, listings, by="neighbourhood", all.y=FALSE)
listings <- listings[-1,]
listings$Cluster <- str_remove(listings$Cluster,"Cluster ")
# Create quantiles
listingsApartment <- listings %>% filter(str_detect(room_type, "room") == FALSE)
listingsApartment$quantile <- as.factor(ntile(listingsApartment$price, 4))
setDT(listingsApartment)
listingsApartment <- listingsApartment[, .(quantile,
Total,
`Min. Nights` = minimum_nights,
`Number of Reviews` = number_of_reviews,
Availability = availability_365,
`Host Listing Count` = calculated_host_listings_count)]
# Implement decision tree protocol
listingsfit <- rpart(quantile ~ Total + `Min. Nights` + `Number of Reviews` + Availability + `Host Listing Count`, data = listingsApartment)
# Plot tree
plot(listingsfit, uniform=TRUE, main="Classification Tree for Listings", margin = 0.05)
text(listingsfit, use.n=TRUE, all=TRUE, cex=.7)
loadPkg("caret")
cm = confusionMatrix(predict(listingsfit, type = "class"), reference = listingsApartment[, quantile])
print('Overall: ')
cm$overall
print('Class: ')
cm$byClass
printcp(listingsfit)
plotcp(listingsfit)
loadPkg("FNN")
scaledListings <- as.data.frame(scale(listingsApartment[,2:6], center = T, scale = T))
set.seed(1)
sample <- sample(2, nrow(scaledListings), replace = T, prob=c(0.67, 0.33))
training <- scaledListings[sample == 1, 1:5]
test <- scaledListings[sample == 2, 1:5]
trainingLabels <- listingsApartment[sample == 1, 1]
testLabels <- listingsApartment[sample == 2, 1]
scaledListings <- as.data.frame(scale(listingsApartment[2:6], center = T, scale = T))
head(iris[1:4])
head(iris[,1:4])
scaledListings <- as.data.frame(scale(listingsApartment[,2:6], center = T, scale = T))
set.seed(1)
sample <- sample(2, nrow(scaledListings), replace = T, prob=c(0.67, 0.33))
training <- scaledListings[sample == 1, 1:5]
test <- scaledListings[sample == 2, 1:5]
trainingLabels <- listingsApartment[sample == 1, 1]
testLabels <- listingsApartment[sample == 2, 1]
listings_pred <- knn(train = training, test = test, cl = trainingLabels, k = 7)
library(FNN)
listings_pred <- knn(train = training, test = test, cl = trainingLabels, k = 7)
cl = trainingLabels[, 1]
listings_pred <- knn(train = training, test = test, cl = trainingLabels, k = 7)
listings_pred <- knn(train = training, test = test, cl, k = 7)
cl = trainingLabels[, 1]
listings_pred <- knn(train = training, test = test, cl, k = 7)
trainingLabels <- as.data.frame(trainingLabels)
listings_pred <- knn(train = training, test = test, cl = trainingLabels, k = 7)
scaledListings <- as.data.frame(scale(listingsApartment[,2:6], center = T, scale = T))
set.seed(1)
sample <- sample(2, nrow(scaledListings), replace = T, prob=c(0.67, 0.33))
training <- scaledListings[sample == 1, 1:5]
test <- scaledListings[sample == 2, 1:5]
trainingLabels <- as.data.frame(listingsApartment[sample == 1, 1])
testLabels <- as.data.frame(listingsApartment[sample == 2, 1])
listings_pred <- knn(train = training, test = test, cl = trainingLabels, k = 7)
cl <- trainingLabels[, 1, drop = T]
listings_pred <- knn(train = training, test = test, cl, k = 7)
loadPkg("gmodels")
loadPkg("pander")
cross_table <- CrossTable(testLabels, listings_pred, prop.chisq = F)
testLabels <- testLabels[, 2, drop = T]
testLabels <- testLabels[, 1, drop = T]
cross_table <- CrossTable(testLabels, listings_pred, prop.chisq = F)
256/690
256/537
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
# can add quietly=T option to the require() function
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
loadPkg("FNN")
#For this example we are going to use the IRIS dataset in R
str(iris)
#first we want to scale the data so KNN will operate correctly
scalediris <- as.data.frame(scale(iris[1:4], center = TRUE, scale = TRUE))
#We also need to create test and train data sets, we will do this slightly differently by using the sample function. The 2 says create 2 data sets essentially, replacement means we can reset the random sampling across each vector and the probability gives sample the weight of the splits, 2/3 for train, 1/3 for test.
set.seed(1000)
iris_sample <- sample(2, nrow(scalediris), replace=TRUE, prob=c(0.67, 0.33))
#We then just need to use the new variable to create the test/train outputs, selecting the first four rows as they are the numeric data in the iris data set and we want to predict Species
iris_training <- scalediris[iris_sample==1, 1:4]
iris_test <- scalediris[iris_sample==2, 1:4]
#Now we need to create our 'Y' variables or labels need to input into the KNN function
iris.trainLabels <- iris[iris_sample==1, 5]
iris.testLabels <- iris[iris_sample==2, 5]
iris_pred <- knn(train = iris_training, test = iris_test, cl=iris.trainLabels, k=6)
iris_pred
#install.packages("gmodels")
loadPkg("gmodels")
IRISPREDCross <- CrossTable(iris.testLabels, iris_pred, prop.chisq = FALSE)
256 + 197 + 140 + 97
256/690
chooseK = function(k, train_set, val_set, train_class, val_class){
# Build knn with k neighbors considered.
set.seed(1)
class_knn = knn(train = train_set,    #<- training set cases
test = val_set,       #<- test set cases
cl = train_class,     #<- category for classification
k = k,                #<- number of neighbors considered
use.all = TRUE)       #<- control ties between class assignments
#   If true, all distances equal to the kth
#   largest are included
tab = table(class_knn, val_class)
# Calculate the accuracy.
accu = sum(tab[row(tab) == col(tab)]) / sum(tab)
cbind(k = k, accuracy = accu)
}
knn_different_k = sapply(seq(1, 21, by = 2),  #<- set k to be odd number from 1 to 21
function(x) chooseK(x,
train_set = training,
val_set = test,
train_class = training[, "quantile"],
val_class = test[, "quantile"]))
knn_different_k = sapply(seq(1, 21, by = 2),
function(x) chooseK(x,
train_set = training,
val_set = test,
train_class = training[, "quantile"],
val_class = test[, "quantile"],
use.all = T))
knn_different_k = sapply(seq(1, 21, by = 2),
function(x) chooseK(x,
train_set = training,
val_set = test,
train_class = training[, "quantile"],
val_class = test[, "quantile"],
use.all = F))
chooseK = function(k, train_set, val_set, train_class, val_class){
# Build knn with k neighbors considered.
set.seed(1)
class_knn = knn(train = train_set,    #<- training set cases
test = val_set,       #<- test set cases
cl = train_class,     #<- category for classification
k = k)               #<- number of neighbors considered
#   If true, all distances equal to the kth
#   largest are included
tab = table(class_knn, val_class)
# Calculate the accuracy.
accu = sum(tab[row(tab) == col(tab)]) / sum(tab)
cbind(k = k, accuracy = accu)
}
knn_different_k = sapply(seq(1, 21, by = 2),
function(x) chooseK(x,
train_set = training,
val_set = test,
train_class = training[, "quantile"],
val_class = test[, "quantile"],
use.all = F))
knn_different_k = sapply(seq(1, 21, by = 2),
function(x) chooseK(x,
train_set = training,
val_set = test,
train_class = training[, "quantile"],
val_class = test[, "quantile"]))
knn_different_k = sapply(seq(1, 21, by = 2),
function(x) chooseK(x,
train_set = scaledListings[sample == 1, 1:5],
val_set = scaledListings[sample == 2, 1:5],
train_class = listingsApartment[, "quantile"],
val_class = listingsApartment[, "quantile"]))
knn_different_k = sapply(seq(1, 21, by = 2),
function(x) chooseK(x,
train_set = scaledListings[sample == 1, 1:5],
val_set = scaledListings[sample == 2, 1:5],
train_class = trainingLabels,
val_class = testLabels))
knn_different_k = sapply(seq(1, 21, by = 2),
function(x) chooseK(x,
train_set = training,
val_set = test,
train_class = trainingLabels,
val_class = testLabels))
scaledListings <- as.data.frame(scale(listingsApartment[,2:6], center = T, scale = T))
set.seed(1)
sample <- sample(2, nrow(scaledListings), replace = T, prob=c(0.67, 0.33))
training <- scaledListings[sample == 1, 1:5]
test <- scaledListings[sample == 2, 1:5]
trainingLabels <- as.data.frame(listingsApartment[sample == 1, 1])
testLabels <- as.data.frame(listingsApartment[sample == 2, 1])
trainingLabels <- trainingLabels[, 1, drop = T]
testLabels <- testLabels[, 1, drop = T]
listings_pred <- knn(train = training, test = test, cl = trainingLabels, k = 7)
cross_table <- CrossTable(testLabels, listings_pred, prop.chisq = F)
chooseK = function(k, train_set, val_set, train_class, val_class){
# Build knn with k neighbors considered.
set.seed(1)
class_knn = knn(train = train_set,    #<- training set cases
test = val_set,       #<- test set cases
cl = train_class,     #<- category for classification
k = k)               #<- number of neighbors considered
#   If true, all distances equal to the kth
#   largest are included
tab = table(class_knn, val_class)
# Calculate the accuracy.
accu = sum(tab[row(tab) == col(tab)]) / sum(tab)
cbind(k = k, accuracy = accu)
}
knn_different_k = sapply(seq(1, 21, by = 2),
function(x) chooseK(x,
train_set = training,
val_set = test,
train_class = trainingLabels,
val_class = testLabels))
knn_different_k = data.frame(k = knn_different_k[1,],
accuracy = knn_different_k[2,])
ggplot(knn_different_k,
aes(x = k, y = accuracy)) +
geom_line(color = "orange", size = 1.5) +
geom_point(size = 3)
ggplot(knn_different_k,
aes(x = k, y = accuracy)) +
geom_line(color = "blue") +
geom_point(size = 3) +
labs(main = "Accuracy Rates of Different k-values",
x = "k-value",
y = "Accuracy") +
theme_bw()
ggplot(knn_different_k,
aes(x = k, y = accuracy)) +
geom_line(color = "blue") +
geom_point(size = 1) +
labs(main = "Accuracy Rates of Different k-values",
x = "k-value",
y = "Accuracy") +
theme_bw()
